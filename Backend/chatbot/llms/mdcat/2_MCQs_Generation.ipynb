{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "if not groq_api_key:\n",
    "    raise ValueError(\"Groq API key not found in .env file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abdul\\miniconda3\\envs\\fyp\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPIEmbeddings has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_groq import ChatGroq\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
    "from reportlab.lib.enums import TA_JUSTIFY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Groq API key\n",
    "os.environ[\"GROQ_API_KEY\"] = groq_api_key  # Replace with your actual Groq API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qa_system(past_paper_paths, subject_book_paths):\n",
    "    all_texts = \"\"\n",
    "    for pdf_path in past_paper_paths + subject_book_paths:\n",
    "        pdf_text = extract_text_from_pdf(pdf_path)\n",
    "        all_texts += pdf_text + \"\\n\"\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    texts = text_splitter.split_text(all_texts)\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings()\n",
    "    db = Chroma.from_texts(texts, embeddings)\n",
    "\n",
    "    llm = ChatGroq(\n",
    "        model=\"llama-3.1-70b-versatile\",\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=db.as_retriever(search_kwargs={\"k\": 3}))\n",
    "\n",
    "    return qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question_paper(qa_system, num_questions):\n",
    "    questions = []\n",
    "    for i in range(num_questions):\n",
    "        prompt = f\"Generate a new multiple choice exam which has 10 questions based on the content of the past papers, ensuring it's within the scope of the subject books. The question should be challenging but fair. Format the question in a structured manner suitable for an exam paper, including clear instructions. give mcqs in the form of a,b,c,d options. also space between each question should be at least 2 lines in proper format.\"\n",
    "        response = qa_system.run(prompt)\n",
    "        questions.append(response)\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reformatted_question_paper_pdf(questions, output_path):\n",
    "    doc = SimpleDocTemplate(output_path, pagesize=letter)\n",
    "    styles = getSampleStyleSheet()\n",
    "    content = []\n",
    "\n",
    "    content.append(Paragraph(\"Generated Question Paper\", styles['Title']))\n",
    "    content.append(Spacer(1, 12))\n",
    "\n",
    "    styles.add(ParagraphStyle(name='Justify', alignment=TA_JUSTIFY))\n",
    "    \n",
    "    for i, question in enumerate(questions, 1):\n",
    "        content.append(Paragraph(f\"Question {i}\", styles['Heading2']))\n",
    "        lines = question.split('\\n')\n",
    "        for line in lines:\n",
    "            if line.strip():\n",
    "                if line.startswith('*') or line.startswith('-'):\n",
    "                    content.append(Paragraph(f\"â€¢ {line.strip('*- ')}\", styles['BodyText']))\n",
    "                else:\n",
    "                    content.append(Paragraph(line, styles['Justify']))\n",
    "        content.append(Spacer(1, 12))\n",
    "\n",
    "    doc.build(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_pdf_files_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Returns a list of PDF file paths from the specified folder.\n",
    "    \"\"\"\n",
    "    pdf_files = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.lower().endswith('.pdf'):\n",
    "            pdf_files.append(os.path.join(folder_path, file))\n",
    "    return pdf_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Get PDFs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_12368\\4250945908.py:10: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings()\n",
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_12368\\4250945908.py:10: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embeddings = HuggingFaceEmbeddings()\n",
      "c:\\Users\\abdul\\miniconda3\\envs\\fyp\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\abdul\\miniconda3\\envs\\fyp\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done QA System\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_12368\\1515914147.py:5: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_system.run(prompt)\n",
      "Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Question Generation\n",
      "Generated question paper has been saved to mcqs_generation_pdfs/multiple choice questions.pdf\n",
      "Used 7 past papers from the folder 'mcqs_output_pdfs'\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    past_paper_folder = \"mcqs_output_pdfs\"  # Folder containing past paper PDFs\n",
    "    past_paper_paths = get_pdf_files_from_folder(past_paper_folder)\n",
    "    print(\"Done Get PDFs\")\n",
    "    # subject_book_paths = [\"books/Biology11.pdf\"]  # Add your subject book PDFs here\n",
    "    subject_book_paths = []\n",
    "    qa_system = create_qa_system(past_paper_paths, subject_book_paths)\n",
    "    print(\"Done QA System\")\n",
    "    num_questions = 1  # You can adjust this number\n",
    "    questions = generate_question_paper(qa_system, num_questions)\n",
    "    print(\"Done Question Generation\")\n",
    "    output_pdf_path = \"mcqs_generation_pdfs/multiple choice questions.pdf\"\n",
    "    create_reformatted_question_paper_pdf(questions, output_pdf_path)\n",
    "    \n",
    "    print(f\"Generated question paper has been saved to {output_pdf_path}\")\n",
    "    print(f\"Used {len(past_paper_paths)} past papers from the folder '{past_paper_folder}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# def main():\n",
    "#     past_paper_paths = [\"output.pdf\", \"output1.pdf\"]  # Your past paper PDFs\n",
    "#     subject_book_paths = [\"cs10.pdf\"]  # Add your subject book PDFs here\n",
    "    \n",
    "#     qa_system = create_qa_system(past_paper_paths, subject_book_paths)\n",
    "    \n",
    "#     num_questions = 10  # You can adjust this number\n",
    "#     questions = generate_question_paper(qa_system, num_questions)\n",
    "\n",
    "#     output_pdf_path = \"r1_generated_question_paper.pdf\"\n",
    "#     create_reformatted_question_paper_pdf(questions, output_pdf_path)\n",
    "#     print(f\"Generated question paper has been saved to {output_pdf_path}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
