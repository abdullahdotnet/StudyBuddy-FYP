{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import gc\n",
    "import logging\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = \"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\"  # Replace with your actual Groq API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting text from PDF: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qa_system(question_paper_path):\n",
    "    question_paper_text = extract_text_from_pdf(question_paper_path)\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    texts = text_splitter.split_text(question_paper_text)\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    db = Chroma.from_texts(texts, embeddings)\n",
    "\n",
    "    llm = ChatGroq(\n",
    "        model=\"llama-3.1-70b-versatile\",\n",
    "        temperature=0.2,\n",
    "        max_tokens=1000,  # Limit token generation\n",
    "    )\n",
    "\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=db.as_retriever(search_kwargs={\"k\": 2}))\n",
    "\n",
    "    return qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mcq_answer(qa_system, question_number, student_answer):\n",
    "    prompt = f\"\"\"\n",
    "    Referring to Multiple Choice Question {question_number}:\n",
    "    \n",
    "    Student's Answer: {student_answer}\n",
    "\n",
    "    Criteria:\n",
    "    1. Correctness: Is the answer correct? (1 point if correct, 0 if incorrect)\n",
    "    2. Validity: Is the response a valid option (A, B, C, or D)?\n",
    "\n",
    "    Instructions:\n",
    "    - Assign 1 point if the answer is correct and valid, 0 points otherwise.\n",
    "    - Provide a brief explanation (1-2 sentences) for the score.\n",
    "    - If the response is invalid, explain why and assign 0 points.\n",
    "\n",
    "    Format your response as follows:\n",
    "    Score: [0 or 1]\n",
    "    Explanation: [Your brief explanation]\n",
    "\n",
    "    Limit your entire response to 50 words.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        evaluation = qa_system.run(prompt)\n",
    "        return evaluation\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during evaluation: {e}\")\n",
    "        return \"Error occurred during evaluation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_student_answers(student_answers_text):\n",
    "    answers = {}\n",
    "    # Split the text into lines\n",
    "    lines = student_answers_text.split('\\n')\n",
    "    \n",
    "    # Regular expression pattern to match \"number. letter\" format\n",
    "    pattern = r'(\\d+)\\.\\s*([A-D])'\n",
    "    \n",
    "    for line in lines:\n",
    "        # Use regex to find matches in each line\n",
    "        match = re.match(pattern, line.strip())\n",
    "        if match:\n",
    "            question_number = match.group(1)\n",
    "            answer = match.group(2)\n",
    "            answers[question_number] = answer\n",
    "    \n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Track Computers\\AppData\\Local\\Temp\\ipykernel_1212\\2518398560.py:7: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
      "d:\\Final Year\\StudyBuddy-FYP\\Backend\\venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "2024-10-13 21:56:15,481 - INFO - Use pytorch device_name: cpu\n",
      "2024-10-13 21:56:15,487 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "2024-10-13 21:56:21,767 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "C:\\Users\\Track Computers\\AppData\\Local\\Temp\\ipykernel_1212\\2165258059.py:24: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  evaluation = qa_system.run(prompt)\n",
      "2024-10-13 21:56:26,538 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Question 1:\n",
      "Score: 0\n",
      "Explanation: The answer is not provided in the given context, so it's impossible to determine the correctness of the student's answer. The context only provides information for questions 4-9, but not question 1.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 21:56:28,181 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Question 2:\n",
      "Score: 1\n",
      "Explanation: The answer is correct and valid. The student chose option B, but the question is not provided. However, based on the context, if the question is related to photosynthesis, transpiration, or evaporation, option B might be correct, but without the question, it's hard to confirm.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 21:56:30,119 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Question 3:\n",
      "Score: 0\n",
      "Explanation: The answer is incorrect because the question is not provided, and I don't know what the question is asking. However, the response \"C\" is a valid option, but without the question, I cannot determine its correctness.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 21:56:31,861 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Question 4:\n",
      "Score: 0\n",
      "Explanation: The answer is incorrect because Thyroxine is produced by the thyroid gland, not the pancreas. The correct answer is A) Insulin, which is produced by the pancreas and plays a key role in regulating blood sugar levels.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 21:56:33,417 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Question 5:\n",
      "Score: 1\n",
      "Explanation: The student's answer, A) Differentiation, is correct and valid. Differentiation is the process by which a cell becomes specialized to perform a specific function, making it the correct choice among the options provided.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 21:56:34,833 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Question 6:\n",
      "Score: 0\n",
      "Explanation: The answer is incorrect because T cells do not produce antibodies in response to infection. B cells are responsible for producing antibodies. The response is a valid option, but the answer is incorrect.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 21:56:36,366 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Question 7:\n",
      "Score: 0\n",
      "Explanation: The answer is incorrect. Natural selection (option C) is the process by which organisms with favorable traits are more likely to survive and reproduce, whereas heredity (option D) is the correct term for the process by which genetic information is passed from one generation to the next.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 21:56:37,809 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Question 8:\n",
      "Score: 0\n",
      "Explanation: The answer is incorrect because the lungs are responsible for exchanging oxygen and carbon dioxide, not filtering waste and excess fluids from the blood. The correct answer is B) Kidneys, which are the primary organs for filtering waste and excess fluids.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 21:56:39,437 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Question 9:\n",
      "Score: 0\n",
      "Explanation: The student's answer, A, is not the correct answer for the question about the term for the process by which an organism's genetic information is altered by external factors. The correct answer is not provided in the given context, but A is not a valid option based on the information given.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 21:56:40,873 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Question 10:\n",
      "I don't know the answer. There is no Multiple Choice Question 10 provided in the given context.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    question_paper_path = r\"mcqs_generation_pdfs/multiple choice questions.pdf\"\n",
    "    student_answers_path = r\"mcqs_answer_pdfs/answer_1.pdf\"\n",
    "    \n",
    "    try:\n",
    "        qa_system = create_qa_system(question_paper_path)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error creating QA system: {e}\")\n",
    "        return\n",
    "\n",
    "    student_answers_text = extract_text_from_pdf(student_answers_path)\n",
    "    student_answers = parse_student_answers(student_answers_text)\n",
    "\n",
    "    for question_number, student_answer in student_answers.items():\n",
    "        evaluation = evaluate_mcq_answer(qa_system, question_number, student_answer)\n",
    "        \n",
    "        print(f\"Evaluation for Question {question_number}:\")\n",
    "        print(evaluation)\n",
    "        print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "        \n",
    "        # Clear some memory after each iteration\n",
    "        gc.collect()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
