{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_groq import ChatGroq\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
    "from reportlab.lib.enums import TA_JUSTIFY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Groq API key\n",
    "os.environ[\"GROQ_API_KEY\"] = \"\"  # Replace with your actual Groq API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qa_system(past_paper_paths, subject_book_paths):\n",
    "    all_texts = \"\"\n",
    "    for pdf_path in past_paper_paths + subject_book_paths:\n",
    "        pdf_text = extract_text_from_pdf(pdf_path)\n",
    "        all_texts += pdf_text + \"\\n\"\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    texts = text_splitter.split_text(all_texts)\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings()\n",
    "    db = Chroma.from_texts(texts, embeddings)\n",
    "\n",
    "    llm = ChatGroq(\n",
    "        model=\"llama-3.1-70b-versatile\",\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=db.as_retriever(search_kwargs={\"k\": 3}))\n",
    "\n",
    "    return qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_question_paper(qa_system, num_questions):\n",
    "#     questions = []\n",
    "#     for i in range(num_questions):\n",
    "#         prompt = f\"Generate a new subjective question paper based on the contents of the past papers, ensuring it's within the scope of the subject books. There should be two sections in the paper, in first section there are three parts of short questions and in each part of short question, there are six short questions. Then in second section, there are three long questions. The question should be challenging but fair. Format the question in a structured manner suitable for an exam paper. also space between each question should be at least 2 lines.\"\n",
    "#         response = qa_system.run(prompt)\n",
    "#         questions.append(response)\n",
    "#     return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question_paper(qa_system, num_questions):\n",
    "    questions = []\n",
    "    for i in range(num_questions):\n",
    "        prompt = f\"Generate a new subjective question paper based on the contents of the past papers, ensuring it's within the scope of the subject books. There should be two sections in the paper, in first section there are three parts of short questions and in each part of short question, there are six short questions. Then in second section, there are three long questions. The question should be challenging but fair. Format the question in a structured manner suitable for an exam paper. also space between each question should be at least 2 lines. donot repeat the questions.\"\n",
    "        response = qa_system.run(prompt)\n",
    "        questions.append(response)\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reformatted_question_paper_pdf(questions, output_path):\n",
    "    doc = SimpleDocTemplate(output_path, pagesize=letter)\n",
    "    styles = getSampleStyleSheet()\n",
    "    content = []\n",
    "\n",
    "    content.append(Paragraph(\"Generated Question Paper\", styles['Title']))\n",
    "    content.append(Spacer(1, 12))\n",
    "\n",
    "    styles.add(ParagraphStyle(name='Justify', alignment=TA_JUSTIFY))\n",
    "    \n",
    "    for i, question in enumerate(questions, 1):\n",
    "        content.append(Paragraph(f\"Question {i}\", styles['Heading2']))\n",
    "        lines = question.split('\\n')\n",
    "        for line in lines:\n",
    "            if line.strip():\n",
    "                if line.startswith('*') or line.startswith('-'):\n",
    "                    content.append(Paragraph(f\"â€¢ {line.strip('*- ')}\", styles['BodyText']))\n",
    "                else:\n",
    "                    content.append(Paragraph(line, styles['Justify']))\n",
    "        content.append(Spacer(1, 12))\n",
    "\n",
    "    doc.build(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_pdf_files_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Returns a list of PDF file paths from the specified folder.\n",
    "    \"\"\"\n",
    "    pdf_files = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.lower().endswith('.pdf'):\n",
    "            pdf_files.append(os.path.join(folder_path, file))\n",
    "    return pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 25338, which is longer than the specified 1000\n",
      "C:\\Users\\PRECISION\\AppData\\Local\\Temp\\ipykernel_8596\\4250945908.py:10: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embeddings = HuggingFaceEmbeddings()\n",
      "c:\\Users\\PRECISION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated question paper has been saved to new_subjective question paper.pdf\n",
      "Used 31 past papers from the folder 'sub_output_pdfs'\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    past_paper_folder = \"sub_output_pdfs\"  # Folder containing past paper PDFs\n",
    "    past_paper_paths = get_pdf_files_from_folder(past_paper_folder)\n",
    "    \n",
    "    subject_book_paths = [\"cs9.pdf\"]  # Add your subject book PDFs here\n",
    "    \n",
    "    qa_system = create_qa_system(past_paper_paths, subject_book_paths)\n",
    "    \n",
    "    num_questions = 1  # You can adjust this number\n",
    "    questions = generate_question_paper(qa_system, num_questions)\n",
    "    \n",
    "    output_pdf_path = \"new_subjective question paper.pdf\"\n",
    "    create_reformatted_question_paper_pdf(questions, output_pdf_path)\n",
    "    \n",
    "    print(f\"Generated question paper has been saved to {output_pdf_path}\")\n",
    "    print(f\"Used {len(past_paper_paths)} past papers from the folder '{past_paper_folder}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     past_paper_paths = [\"output.pdf\", \"output1.pdf\"]  # Your past paper PDFs\n",
    "#     subject_book_paths = [\"cs10.pdf\"]  # Add your subject book PDFs here\n",
    "    \n",
    "#     qa_system = create_qa_system(past_paper_paths, subject_book_paths)\n",
    "    \n",
    "#     num_questions = 10  # You can adjust this number\n",
    "#     questions = generate_question_paper(qa_system, num_questions)\n",
    "\n",
    "#     output_pdf_path = \"r1_generated_question_paper.pdf\"\n",
    "#     create_reformatted_question_paper_pdf(questions, output_pdf_path)\n",
    "#     print(f\"Generated question paper has been saved to {output_pdf_path}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
