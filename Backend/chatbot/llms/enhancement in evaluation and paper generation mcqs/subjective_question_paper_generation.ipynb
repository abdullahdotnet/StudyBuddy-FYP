{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_groq import ChatGroq\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
    "from reportlab.lib.enums import TA_JUSTIFY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import groq API key from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qa_system(past_paper_paths, subject_book_paths):\n",
    "    all_texts = \"\"\n",
    "    for pdf_path in past_paper_paths + subject_book_paths:\n",
    "        pdf_text = extract_text_from_pdf(pdf_path)\n",
    "        all_texts += pdf_text + \"\\n\"\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    texts = text_splitter.split_text(all_texts)\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings()\n",
    "    # see dimensions of the embeddings and texts\n",
    "    print(embeddings.embed(texts[0]).shape)\n",
    "    print(texts[0])\n",
    "    db = Chroma.from_texts(texts, embeddings)\n",
    "\n",
    "    llm = ChatGroq(\n",
    "        model=\"llama-3.1-70b-versatile\",\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=db.as_retriever(search_kwargs={\"k\": 3}))\n",
    "\n",
    "    return qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_question_paper(qa_system, num_questions):\n",
    "#     questions = []\n",
    "#     for i in range(num_questions):\n",
    "#         prompt = f\"Generate a new subjective question paper based on the contents of the past papers, ensuring it's within the scope of the subject books. There should be two sections in the paper, in first section there are three parts of short questions and in each part of short question, there are six short questions. Then in second section, there are three long questions. The question should be challenging but fair. Format the question in a structured manner suitable for an exam paper. also space between each question should be at least 2 lines.\"\n",
    "#         response = qa_system.run(prompt)\n",
    "#         questions.append(response)\n",
    "#     return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question_paper(qa_system, num_questions):\n",
    "    questions = []\n",
    "    for i in range(num_questions):\n",
    "        prompt = f\"Generate a new subjective question paper based on the contents of the past papers, ensuring it's within the scope of the subject books. There should be two sections in the paper, in first section there are three parts of short questions and in each part of short question, there are six short questions. Then in second section, there are three long questions. The question should be challenging but fair. Format the question in a structured manner suitable for an exam paper. also space between each question should be at least 2 lines. donot repeat the questions.\"\n",
    "        response = qa_system.run(prompt)\n",
    "        questions.append(response)\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reformatted_question_paper_pdf(questions, output_path):\n",
    "    doc = SimpleDocTemplate(output_path, pagesize=letter)\n",
    "    styles = getSampleStyleSheet()\n",
    "    content = []\n",
    "\n",
    "    content.append(Paragraph(\"Generated Question Paper\", styles['Title']))\n",
    "    content.append(Spacer(1, 12))\n",
    "\n",
    "    styles.add(ParagraphStyle(name='Justify', alignment=TA_JUSTIFY))\n",
    "    \n",
    "    for i, question in enumerate(questions, 1):\n",
    "        content.append(Paragraph(f\"Question {i}\", styles['Heading2']))\n",
    "        lines = question.split('\\n')\n",
    "        for line in lines:\n",
    "            if line.strip():\n",
    "                if line.startswith('*') or line.startswith('-'):\n",
    "                    content.append(Paragraph(f\"â€¢ {line.strip('*- ')}\", styles['BodyText']))\n",
    "                else:\n",
    "                    content.append(Paragraph(line, styles['Justify']))\n",
    "        content.append(Spacer(1, 12))\n",
    "\n",
    "    doc.build(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_pdf_files_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Returns a list of PDF file paths from the specified folder.\n",
    "    \"\"\"\n",
    "    pdf_files = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.lower().endswith('.pdf'):\n",
    "            pdf_files.append(os.path.join(folder_path, file))\n",
    "    return pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 25338, which is longer than the specified 1000\n",
      "C:\\Users\\zubay\\AppData\\Local\\Temp\\ipykernel_16204\\2691119666.py:10: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embeddings = HuggingFaceEmbeddings()\n",
      "c:\\Users\\zubay\\.conda\\envs\\fyp\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'HuggingFaceEmbeddings' object has no attribute 'embed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(past_paper_paths)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m past papers from the folder \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpast_paper_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[30], line 7\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m past_paper_paths \u001b[38;5;241m=\u001b[39m get_pdf_files_from_folder(past_paper_folder)\n\u001b[0;32m      5\u001b[0m subject_book_paths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcs9.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# Add your subject book PDFs here\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m qa_system \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_qa_system\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast_paper_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject_book_paths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m num_questions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# You can adjust this number\u001b[39;00m\n\u001b[0;32m     10\u001b[0m questions \u001b[38;5;241m=\u001b[39m generate_question_paper(qa_system, num_questions)\n",
      "Cell \u001b[1;32mIn[25], line 12\u001b[0m, in \u001b[0;36mcreate_qa_system\u001b[1;34m(past_paper_paths, subject_book_paths)\u001b[0m\n\u001b[0;32m     10\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m HuggingFaceEmbeddings()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# see dimensions of the embeddings and texts\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m(texts[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(texts[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     14\u001b[0m db \u001b[38;5;241m=\u001b[39m Chroma\u001b[38;5;241m.\u001b[39mfrom_texts(texts, embeddings)\n",
      "File \u001b[1;32mc:\\Users\\zubay\\.conda\\envs\\fyp\\Lib\\site-packages\\pydantic\\main.py:856\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'HuggingFaceEmbeddings' object has no attribute 'embed'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    past_paper_folder = \"sub_output_pdfs\"  # Folder containing past paper PDFs\n",
    "    past_paper_paths = get_pdf_files_from_folder(past_paper_folder)\n",
    "    \n",
    "    subject_book_paths = [\"cs9.pdf\"]  # Add your subject book PDFs here\n",
    "    \n",
    "    qa_system = create_qa_system(past_paper_paths, subject_book_paths)\n",
    "    \n",
    "    num_questions = 1  # You can adjust this number\n",
    "    questions = generate_question_paper(qa_system, num_questions)\n",
    "    \n",
    "    output_pdf_path = \"new_subjective question paper.pdf\"\n",
    "    create_reformatted_question_paper_pdf(questions, output_pdf_path)\n",
    "    \n",
    "    print(f\"Generated question paper has been saved to {output_pdf_path}\")\n",
    "    print(f\"Used {len(past_paper_paths)} past papers from the folder '{past_paper_folder}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     past_paper_paths = [\"output.pdf\", \"output1.pdf\"]  # Your past paper PDFs\n",
    "#     subject_book_paths = [\"cs10.pdf\"]  # Add your subject book PDFs here\n",
    "    \n",
    "#     qa_system = create_qa_system(past_paper_paths, subject_book_paths)\n",
    "    \n",
    "#     num_questions = 10  # You can adjust this number\n",
    "#     questions = generate_question_paper(qa_system, num_questions)\n",
    "\n",
    "#     output_pdf_path = \"r1_generated_question_paper.pdf\"\n",
    "#     create_reformatted_question_paper_pdf(questions, output_pdf_path)\n",
    "#     print(f\"Generated question paper has been saved to {output_pdf_path}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
