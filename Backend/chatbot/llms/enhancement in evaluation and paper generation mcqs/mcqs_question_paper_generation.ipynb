{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PRECISION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPIEmbeddings has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_groq import ChatGroq\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
    "from reportlab.lib.enums import TA_JUSTIFY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Groq API key\n",
    "os.environ[\"GROQ_API_KEY\"] = \"\"  # Replace with your actual Groq API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qa_system(past_paper_paths, subject_book_paths):\n",
    "    all_texts = \"\"\n",
    "    for pdf_path in past_paper_paths + subject_book_paths:\n",
    "        pdf_text = extract_text_from_pdf(pdf_path)\n",
    "        all_texts += pdf_text + \"\\n\"\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    texts = text_splitter.split_text(all_texts)\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings()\n",
    "    db = Chroma.from_texts(texts, embeddings)\n",
    "\n",
    "    llm = ChatGroq(\n",
    "        model=\"llama-3.1-70b-versatile\",\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=db.as_retriever(search_kwargs={\"k\": 3}))\n",
    "\n",
    "    return qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question_paper(qa_system, num_questions):\n",
    "    questions = []\n",
    "    for i in range(num_questions):\n",
    "        prompt = f\"Generate a new multiple choice exam which has 10 questions based on the content of the past papers, ensuring it's within the scope of the subject books. The question should be challenging but fair. Format the question in a structured manner suitable for an exam paper, including clear instructions. give mcqs in the form of a,b,c,d options. also space between each question should be at least 2 lines in proper format.\"\n",
    "        response = qa_system.run(prompt)\n",
    "        questions.append(response)\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reformatted_question_paper_pdf(questions, output_path):\n",
    "    doc = SimpleDocTemplate(output_path, pagesize=letter)\n",
    "    styles = getSampleStyleSheet()\n",
    "    content = []\n",
    "\n",
    "    content.append(Paragraph(\"Generated Question Paper\", styles['Title']))\n",
    "    content.append(Spacer(1, 12))\n",
    "\n",
    "    styles.add(ParagraphStyle(name='Justify', alignment=TA_JUSTIFY))\n",
    "    \n",
    "    for i, question in enumerate(questions, 1):\n",
    "        content.append(Paragraph(f\"Question {i}\", styles['Heading2']))\n",
    "        lines = question.split('\\n')\n",
    "        for line in lines:\n",
    "            if line.strip():\n",
    "                if line.startswith('*') or line.startswith('-'):\n",
    "                    content.append(Paragraph(f\"â€¢ {line.strip('*- ')}\", styles['BodyText']))\n",
    "                else:\n",
    "                    content.append(Paragraph(line, styles['Justify']))\n",
    "        content.append(Spacer(1, 12))\n",
    "\n",
    "    doc.build(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_pdf_files_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Returns a list of PDF file paths from the specified folder.\n",
    "    \"\"\"\n",
    "    pdf_files = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.lower().endswith('.pdf'):\n",
    "            pdf_files.append(os.path.join(folder_path, file))\n",
    "    return pdf_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 26485, which is longer than the specified 1000\n",
      "C:\\Users\\PRECISION\\AppData\\Local\\Temp\\ipykernel_17080\\4250945908.py:10: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings()\n",
      "C:\\Users\\PRECISION\\AppData\\Local\\Temp\\ipykernel_17080\\4250945908.py:10: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embeddings = HuggingFaceEmbeddings()\n",
      "c:\\Users\\PRECISION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\PRECISION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\PRECISION\\AppData\\Local\\Temp\\ipykernel_17080\\784839829.py:5: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_system.run(prompt)\n",
      "Number of requested results 3 is greater than number of elements in index 2, updating n_results = 2\n",
      "Number of requested results 3 is greater than number of elements in index 2, updating n_results = 2\n",
      "Number of requested results 3 is greater than number of elements in index 2, updating n_results = 2\n",
      "Number of requested results 3 is greater than number of elements in index 2, updating n_results = 2\n",
      "Number of requested results 3 is greater than number of elements in index 2, updating n_results = 2\n",
      "Number of requested results 3 is greater than number of elements in index 2, updating n_results = 2\n",
      "Number of requested results 3 is greater than number of elements in index 2, updating n_results = 2\n",
      "Number of requested results 3 is greater than number of elements in index 2, updating n_results = 2\n",
      "Number of requested results 3 is greater than number of elements in index 2, updating n_results = 2\n",
      "Number of requested results 3 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated question paper has been saved to multiple choice questions.pdf\n",
      "Used 33 past papers from the folder 'output_pdfs'\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    past_paper_folder = \"mcqs_output_pdfs\"  # Folder containing past paper PDFs\n",
    "    past_paper_paths = get_pdf_files_from_folder(past_paper_folder)\n",
    "    \n",
    "    subject_book_paths = [\"cs9.pdf\"]  # Add your subject book PDFs here\n",
    "    \n",
    "    qa_system = create_qa_system(past_paper_paths, subject_book_paths)\n",
    "    \n",
    "    num_questions = 1  # You can adjust this number\n",
    "    questions = generate_question_paper(qa_system, num_questions)\n",
    "    \n",
    "    output_pdf_path = \"multiple choice questions.pdf\"\n",
    "    create_reformatted_question_paper_pdf(questions, output_pdf_path)\n",
    "    \n",
    "    print(f\"Generated question paper has been saved to {output_pdf_path}\")\n",
    "    print(f\"Used {len(past_paper_paths)} past papers from the folder '{past_paper_folder}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     past_paper_paths = [\"output.pdf\", \"output1.pdf\"]  # Your past paper PDFs\n",
    "#     subject_book_paths = [\"cs10.pdf\"]  # Add your subject book PDFs here\n",
    "    \n",
    "#     qa_system = create_qa_system(past_paper_paths, subject_book_paths)\n",
    "    \n",
    "#     num_questions = 10  # You can adjust this number\n",
    "#     questions = generate_question_paper(qa_system, num_questions)\n",
    "\n",
    "#     output_pdf_path = \"r1_generated_question_paper.pdf\"\n",
    "#     create_reformatted_question_paper_pdf(questions, output_pdf_path)\n",
    "#     print(f\"Generated question paper has been saved to {output_pdf_path}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Backend-S4Q20Ayg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
