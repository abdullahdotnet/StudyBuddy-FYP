{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from groq import Groq\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    #\n",
    "    # Required parameters\n",
    "    #\n",
    "    messages=[\n",
    "        # Set an optional system message. This sets the behavior of the\n",
    "        # assistant and can be used to provide specific instructions for\n",
    "        # how it should behave throughout the conversation.\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"you are a helpful assistant.\"\n",
    "        },\n",
    "        # Set a user message for the assistant to respond to.\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    # The language model which will generate the completion.\n",
    "    model=\"llama3-8b-8192\",\n",
    "\n",
    "    #\n",
    "    # Optional parameters\n",
    "    #\n",
    "\n",
    "    # Controls randomness: lowering results in less random completions.\n",
    "    # As the temperature approaches zero, the model will become deterministic\n",
    "    # and repetitive.\n",
    "    temperature=0.5,\n",
    "\n",
    "    # The maximum number of tokens to generate. Requests can use up to\n",
    "    # 32,768 tokens shared between prompt and completion.\n",
    "    # max_tokens=1024,\n",
    "\n",
    "    # Controls diversity via nucleus sampling: 0.5 means half of all\n",
    "    # likelihood-weighted options are considered.\n",
    "    top_p=1,\n",
    "\n",
    "    # A stop sequence is a predefined or user-specified text string that\n",
    "    # signals an AI to stop generating content, ensuring its responses\n",
    "    # remain focused and concise. Examples include punctuation marks and\n",
    "    # markers like \"[end]\".\n",
    "    stop=None,\n",
    "\n",
    "    # If set, partial message deltas will be sent.\n",
    "    stream=False,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are a type of artificial intelligence (AI) model that are designed to process and generate human-like language quickly and efficiently. They have become increasingly important in recent years due to their numerous applications and benefits. Here are some reasons why fast language models are important:\n",
      "\n",
      "1. **Improved Conversational AI**: Fast language models enable chatbots and virtual assistants to respond quickly and accurately to user queries, leading to better customer experiences and increased user engagement.\n",
      "2. **Enhanced Language Translation**: Fast language models can translate text and speech in real-time, making them essential for applications such as language learning, travel, and international business.\n",
      "3. **Content Generation**: Fast language models can generate high-quality content quickly, such as articles, social media posts, and product descriptions, making them valuable for content creation and marketing.\n",
      "4. **Sentiment Analysis and Opinion Mining**: Fast language models can analyze large amounts of text data quickly, enabling businesses to gain insights into customer opinions, sentiment, and preferences.\n",
      "5. **Text Summarization**: Fast language models can summarize long documents and articles quickly, making it easier for users to quickly grasp the main points and key information.\n",
      "6. **Question Answering**: Fast language models can quickly answer complex questions, making them useful for applications such as customer support, knowledge management, and research.\n",
      "7. **Improved Search Engines**: Fast language models can help improve search engine results by quickly analyzing and understanding the context and intent behind user queries.\n",
      "8. **Healthcare and Medical Research**: Fast language models can quickly analyze large amounts of medical literature, enabling researchers to identify patterns, trends, and correlations that can lead to breakthroughs in medical research.\n",
      "9. **Cybersecurity**: Fast language models can quickly analyze and detect malicious language patterns, helping to prevent cyberattacks and improve online security.\n",
      "10. **Cost Savings**: Fast language models can automate many language-related tasks, reducing the need for human intervention and saving time and resources.\n",
      "\n",
      "In summary, fast language models have the potential to revolutionize the way we interact with language and technology, enabling faster, more accurate, and more efficient processing and generation of human-like language.\n"
     ]
    }
   ],
   "source": [
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models have gained significant attention in recent years due to their numerous applications and benefits. Here are some of the key reasons why fast language models are important:\n",
      "\n",
      "1. **Speed and Efficiency**: Fast language models can process and generate text at a much faster rate than traditional language models. This is particularly important in applications where speed and efficiency are crucial, such as chatbots, virtual assistants, and natural language processing (NLP) pipelines.\n",
      "\n",
      "2. **Scalability**: Fast language models can handle large volumes of data and scale to meet the demands of big data applications. This makes them ideal for use cases such as text classification, sentiment analysis, and language translation.\n",
      "\n",
      "3. **Real-time Processing**: Fast language models enable real-time processing of text data, which is essential for applications such as speech recognition, language translation, and text summarization.\n",
      "\n",
      "4. **Improved User Experience**: Fast language models can provide instant responses to user queries, which can significantly improve the user experience in applications such as customer service chatbots, virtual assistants, and language translation apps.\n",
      "\n",
      "5. **Enhanced AI Capabilities**: Fast language models can be used to improve the capabilities of artificial intelligence (AI) systems, such as machine learning models, by providing them with more accurate and relevant data.\n",
      "\n",
      "6. **Competitive Advantage**: Fast language models can provide a competitive advantage in industries such as finance, healthcare, and e-commerce, where speed and accuracy are critical.\n",
      "\n",
      "7. **Cost-Effective**: Fast language models can be more cost-effective than traditional language models, as they require less computational resources and can be trained on smaller datasets.\n",
      "\n",
      "8. **Improved Accuracy**: Fast language models can be trained on large datasets and fine-tuned for specific tasks, which can improve their accuracy and performance.\n",
      "\n",
      "9. **New Applications**: Fast language models have enabled the development of new applications and use cases, such as language translation, text summarization, and chatbots.\n",
      "\n",
      "10. **Future of NLP**: Fast language models are expected to play a crucial role in the future of NLP, enabling the development of more sophisticated AI systems and applications.\n",
      "\n",
      "In summary, fast language models are important because they offer speed, efficiency, scalability, and improved accuracy, which can be used to develop more sophisticated AI systems and applications.None"
     ]
    }
   ],
   "source": [
    "# Print the completion returned by the LLM.\n",
    "for chunk in chat_completion:\n",
    "    print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
